{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOklyu5b0VTvm7R/Gzlbp8z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nbeaudoin/RAG-from-scratch/blob/main/RAG_from_Scratch_Part_1_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment setup"
      ],
      "metadata": {
        "id": "0AL9ysBYjnvh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "bvSCtcfnjh2q"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain_community tiktoken langchain-openai langchainhub chromadb langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Overview"
      ],
      "metadata": {
        "id": "lOqYzeUSkuRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "import os\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "Qjyq8YJujx0Q"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'"
      ],
      "metadata": {
        "id": "kgd4mDXOxuth"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY = userdata.get('openai_api_key')\n",
        "LANGCHAIN_API_KEY = userdata.get('langchain_api_key')"
      ],
      "metadata": {
        "id": "sTRyUds-jzsB"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This seems redundant but whatever\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "os.environ['LANGCHAIN_API_KEY'] = LANGCHAIN_API_KEY"
      ],
      "metadata": {
        "id": "4GawmHnJnneh"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Indexing\n",
        "\n",
        "This function retrieves the webpage and scrapes the content."
      ],
      "metadata": {
        "id": "Aw_Z6gWOk431"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load documents\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    )\n",
        ")\n",
        "docs = loader.load()\n",
        "#docs"
      ],
      "metadata": {
        "id": "_tkeH-rRk24r"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split"
      ],
      "metadata": {
        "id": "cfeoLI8oll3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "#splits"
      ],
      "metadata": {
        "id": "91wTaa6tltQ-"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=OpenAIEmbeddings())\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "_s_FRJhtnYxZ"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retriever and Generation"
      ],
      "metadata": {
        "id": "oXFE76GwoAWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ],
      "metadata": {
        "id": "skCzTK3Gn9bT"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "n9HnEED_oF2r"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Post-processing\n",
        "def format_docs(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "vjMeaQKcoNF0"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "JklKuRVmoUVr"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question (from docs)\n",
        "rag_chain.invoke(\"What is Task Decomposition?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "CRzuAvw6ojA7",
        "outputId": "c56f719c-9d89-4587-dce1-c06784e7337f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It involves transforming big tasks into multiple manageable tasks to enhance model performance. This process can be done through prompting techniques like Chain of Thought or Tree of Thoughts.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question (not from docs)\n",
        "rag_chain.invoke(\"What is the capital of France?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8HS2nwm0oms7",
        "outputId": "209b500a-5a9c-4f2c-c66d-14c430cecabf"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't know.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indexing"
      ],
      "metadata": {
        "id": "JOefexSFpIyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Documents\n",
        "question = \"What kinds of food do I like?\"\n",
        "document = \"My favorite food is sushi\""
      ],
      "metadata": {
        "id": "bz15Q8j4oxKz"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "  \"\"\"Returns the number of tokens in a text string\"\"\"\n",
        "  encoding = tiktoken.get_encoding(encoding_name)\n",
        "  num_tokens = len(encoding.encode(string))\n",
        "  return num_tokens\n",
        "\n",
        "num_tokens_from_string(question, \"cl100k_base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr3cZtovpSsI",
        "outputId": "6a19b199-5c75-4f0a-813f-4efaf6cd83a7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embd = OpenAIEmbeddings()\n",
        "query_result = embd.embed_query(question)\n",
        "document_result = embd.embed_query(document)\n",
        "len(query_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bx2msHfqBbs",
        "outputId": "d76c0a90-8f9a-4b78-c5a7-38f0ce257738"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "  dot_product = np.dot(vec1, vec2)\n",
        "  norm_vec1 = np.linalg.norm(vec1)\n",
        "  norm_vec2 = np.linalg.norm(vec2)\n",
        "  return dot_product / (norm_vec1 * norm_vec2)\n",
        "\n",
        "similarity = cosine_similarity(query_result, document_result)\n",
        "print(\"Cosine Similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spwOtCVLqSTn",
        "outputId": "c99fd23f-7e0d-483b-fe0f-25690d3a3499"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine Similarity: 0.844992945707835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load documents\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "blog_docs = loader.load()"
      ],
      "metadata": {
        "id": "AsmxtHMwsnVm"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "\n",
        "# Make splits\n",
        "splits = text_splitter.split_documents(blog_docs)"
      ],
      "metadata": {
        "id": "GP-04r9qs32q"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=OpenAIEmbeddings())\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "ajkAP8lctIeH"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Retrieval"
      ],
      "metadata": {
        "id": "W-4w63-0t0J0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Index\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=OpenAIEmbeddings())\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1}) ### number of nearby neighbors to fetch"
      ],
      "metadata": {
        "id": "0KCGGFuktsbA"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"What is Task Decomposition?\")"
      ],
      "metadata": {
        "id": "tB2iD8etwBvZ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GcnXXTPwPTm",
        "outputId": "1910cf99-3ee9-4a52-9f66-f724ac5431a4"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-TGrQWr_wRU4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}